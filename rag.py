from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.vectorstores import Chroma
from langchain_core.runnables import RunnablePassthrough
import gradio as gr
import re
import json
from pathlib import Path
import math
import html
from urllib.parse import urlparse
from datetime import date, datetime
from datetime import datetime as dt, timedelta
from gradio_flatpickr_calendar import Calendar

try:
    from zoneinfo import ZoneInfo
    KST = ZoneInfo("Asia/Seoul")
except Exception:
    KST = None

# â˜… ì¶”ê°€: ìœ ëŸ½ 5ëŒ€ ë¦¬ê·¸(API-FOOTBALL ë¦¬ê·¸ ID)
LEAGUE_ID = {
    "EPL": 39,         # ì‰ê¸€ëœë“œ í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸
    "LALIGA": 140,     # ìŠ¤í˜ì¸ ë¼ë¦¬ê°€
    "SERIEA": 135,     # ì´íƒˆë¦¬ì•„ ì„¸ë¦¬ì— A
    "BUNDES": 78,      # ë…ì¼ ë¶„ë°ìŠ¤ë¦¬ê°€
    "LIGUE1": 61,      # í”„ë‘ìŠ¤ ë¦¬ê·¸ 1
}

# matches: ê²½ê¸° ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
# keep_ids: ì‚¬ìš©ìê°€ ì²´í¬ë°•ìŠ¤ë¡œ ì„ íƒí•œ ë¦¬ê·¸ id
def _filter_by_league_ids(matches: list[dict], keep_ids: set[int]) -> list[dict]:
    """league_id ê°€ keep_ids ì•ˆì— ìˆëŠ” ê²½ê¸°ë§Œ ë‚¨ê¹€. keep_idsê°€ ë¹„ì–´ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜."""
    if not keep_ids:
        return matches
    out = []
    for m in matches or []:
        try:
            lid = int(m.get("league_id") or -1)
        except Exception:
            lid = -1
        if lid in keep_ids:
            out.append(m)
    return out


def apply_preset(preset: str):
    """í”„ë¦¬ì…‹ â†’ (ì‹œì‘ì¼, ì¢…ë£Œì¼) 'YYYY-MM-DD' ë¬¸ìì—´ íŠœí”Œ. ì˜ëª»ëœ í”„ë¦¬ì…‹ì´ë©´ ë¹ˆ ë¬¸ìì—´."""
    if not preset or preset == "ë‚ ì§œ ì§€ì • ì•ˆí•¨":
        return "", ""

    now = dt.now(KST) if KST else dt.now()
    today = now.date()

    if preset == "ì˜¤ëŠ˜":
        s = e = today
    elif preset == "ì–´ì œ":
        d1 = today - timedelta(days=1)
        s = e = d1
    elif preset == "ìµœê·¼ 7ì¼":
        s, e = today - timedelta(days=6), today
    elif preset == "ìµœê·¼ 30ì¼":
        s, e = today - timedelta(days=29), today
    elif preset == "ì´ë²ˆ ì£¼":
        s = today - timedelta(days=today.weekday())  # ì›”ìš”ì¼ ì‹œì‘
        e = s + timedelta(days=6)
    elif preset == "ì´ë²ˆ ë‹¬":
        s = today.replace(day=1)
        nm = (s.replace(year=s.year+1, month=1, day=1)
              if s.month == 12 else s.replace(month=s.month+1, day=1))
        e = (nm - timedelta(days=1))
    elif preset == "ì§€ë‚œ ë‹¬":
        first_this = today.replace(day=1)
        e = first_this - timedelta(days=1)
        s = e.replace(day=1)
    else:
        return "", ""  # íƒ€ì… ì¼ê´€ì„±

    return s.isoformat(), e.isoformat()

last_final_docs = []  # ë§ˆì§€ë§‰ ê²€ìƒ‰ ê²°ê³¼(ë§í¬ ì „ë‹¬ìš©)

# â€œYYYY-MM-DDâ€ ë¬¸ìì—´ë¡œ ì •ê·œí™”
def _normalize_date_input(x):
    if not x: return None
    try:
        if isinstance(x, str): return x[:10]
        if hasattr(x, "strftime"): return x.strftime("%Y-%m-%d")
    except Exception:
        pass
    return None

# apiì˜ stats.ë§Œ ê°€ì ¸ì™€ ì €ì¥í•œ ì„ ìˆ˜ ìŠ¤íƒ¯ rows â†’ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ìš”ì•½ ë¬¸ìì—´ ë³€í™˜

import analysis

# ì‚¬ìš©ìê°€ ì„ íƒí•œ ë¦¬ê·¸ì˜ ì •ë³´ë¥¼ í†µí•´ ê²½ê¸°ë¥¼ í•„í„°ë§í•˜ê³  ë“œë¡­ë‹¤ìš´ ìƒì„±
def ui_load_matches_selectable(date_value, use_epl: bool, use_laliga: bool, use_seriea: bool, use_bundes: bool, use_ligue1: bool):
    d = _normalize_date_input(date_value)
    if not d:
        return "<em>ë‚ ì§œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.</em>", gr.update(choices=[], value=None), []

    try:
        # â˜… API-FOOTBALLë§Œ ì‚¬ìš©
        matches = analysis.fetch_matches_official(d, tz="Asia/Seoul")

        # â˜… ì²´í¬ëœ ë¦¬ê·¸ë§Œ ë‚¨ê¸°ê¸°
        selected_ids = set()
        if use_epl:     selected_ids.add(LEAGUE_ID["EPL"])
        if use_laliga:  selected_ids.add(LEAGUE_ID["LALIGA"])
        if use_seriea:  selected_ids.add(LEAGUE_ID["SERIEA"])
        if use_bundes:  selected_ids.add(LEAGUE_ID["BUNDES"])
        if use_ligue1:  selected_ids.add(LEAGUE_ID["LIGUE1"])

        matches = _filter_by_league_ids(matches, selected_ids)

        # í‘œ ë Œë” (render_matches_html ìˆìœ¼ë©´ ì‚¬ìš©)
        html_table = analysis.render_matches_html(matches, with_links=False) # with_links ì—†ì• ë„ ë ê±° ê°™ì€ë° ì¼ë‹¨ ë³´ë¥˜

        # ë“œë¡­ë‹¤ìš´ ì±„ìš°ê¸°
        choices = []
        for i, m in enumerate(matches):
            mid = str(m.get("match_id") or "")
            lab = f"{i:02d}. {m.get('kickoff_local','')} | {m.get('league','')} | {m.get('home','?')} vs {m.get('away','?')} (ID:{mid})"
            choices.append((lab, mid))
        default_val = choices[0][1] if choices else None

        return html_table, gr.update(choices=choices, value=default_val), matches
    except Exception as e:
        return f"<em>ê²½ê¸° ë¶ˆëŸ¬ì˜¤ê¸° ì˜¤ë¥˜: {e}</em>", gr.update(choices=[], value=None), []


def ui_fetch_player_stats(fixture_id: str):
    if not fixture_id:
        return "<em>ê²½ê¸°ë¥¼ ë¨¼ì € ì„ íƒí•˜ì„¸ìš”.</em>", {}

    try:
        rows, raw = analysis.fetch_player_stats_official(str(fixture_id)) # raw: api ì›ë³¸ ë°ì´í„°
        html_table = analysis.render_player_stats_html(rows)
        return html_table, {"rows": rows}
    except Exception as e:
        return f"<em>ì„ ìˆ˜ ìŠ¤íƒ¯ ë¶ˆëŸ¬ì˜¤ê¸° ì˜¤ë¥˜: {e}</em>", {}


parser = StrOutputParser()  # (ì´ë¯¸ ìˆìœ¼ë©´ ì¬ì‚¬ìš©)

import openai

#gptí•œí…Œ ì‹œì¼œì„œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
def _detect_stats_mode(q: str) -> str:
    """
    GPTë¥¼ ì´ìš©í•´ ì§ˆë¬¸ì„ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜:
    'formation' | 'player_comp' | 'tactical' | 'timeline' | 'why'
    """
    prompt = f"""
        ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì¶•êµ¬ ì§ˆë¬¸ì„ ë¶„ë¥˜í•˜ëŠ” AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
        ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ì¹´í…Œê³ ë¦¬ë¡œë§Œ ë¶„ë¥˜í•˜ì„¸ìš”:

        - formation: í¬ë©”ì´ì…˜, ë¼ì¸ì—…, ì„ ë°œ ê´€ë ¨
        - player_comp: ì„ ìˆ˜ ë¹„êµ, vs, ëˆ„ê°€ ë” ì˜í–ˆëŠ”ì§€
        - tactical: ì „ìˆ  ê´€ë ¨ (í”„ë ˆì‹±, ì „í™˜, ë¼ì¸ ë“±)
        - timeline: ëª‡ ë¶„ì— ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€ (ì‹œê°„ ì¤‘ì‹¬ ì§ˆë¬¸)
        - why: ì™œ ì¡ŒëŠ”ì§€, ì™œ ì´ê²¼ëŠ”ì§€, ì›ì¸, ë¶„ì„
        - freeform: ìœ„ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ììœ  ì§ˆë¬¸

        **ì˜¤ì§ ì•„ë˜ ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”** (ë‹¤ë¥¸ ë§ ì—†ì´):  
        player_comp / tactical / timeline / why / freeform

        ì§ˆë¬¸: \"{q}\"
        ë‹µë³€:
        """

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",  # ë˜ëŠ” gpt-3.5-turbo
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0,
        )

        result = response.choices[0].message.content.strip().lower()

        # ë°©ì–´ì½”ë“œ: í˜¹ì‹œë‚˜ GPTê°€ ì´ìƒí•œ ë¬¸ìì—´ì„ ë°˜í™˜í•  ê²½ìš°
        valid = {"formation", "player_comp", "tactical", "timeline", "why", "freeform"}
        return result if result in valid else "freeform"

    except Exception as e:
        print(f"GPT ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
        return "freeform"

#ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ë‹¤ë¥´ê²Œ í•´ì„œ ë‹µë³€ í¬ë©”ì´ì…˜ ë¶€ë¶„ì€ ë‚˜ì¤‘ì— ê°œì„ , maxtokenë„ ë‚˜ì¤‘ì— ìƒê°
def _build_prompt_for_mode(
    mode: str,
    q: str,
    full_ctx_json: str,
    max_tokens: int = 2000,
    config: dict | None = None,
):
    if config is None:
        config = {}

    parser = StrOutputParser()

    model_name = config.get("llm_stats_model", "gpt-4o-mini")
    llm = ChatOpenAI(
        model=model_name,
        temperature=0.2,
        max_tokens=int(config.get("llm_stats_max_tokens", max_tokens))
    )

    # ----------------------------------------------------
    # 1) ì„ ìˆ˜ ë¹„êµ (player_comp)
    # ----------------------------------------------------
    if mode == "player_comp":
        prompt = ChatPromptTemplate.from_messages([
            ("system", "ë„ˆëŠ” ì„ ìˆ˜ ë°ì´í„°ë¥¼ ë¹„êµ ë¶„ì„í•˜ëŠ” ì¶•êµ¬ í†µê³„ ì „ë¬¸ê°€ë‹¤.\n"
                       "ë°˜ë“œì‹œ JSON ë°ì´í„°ë§Œ ê·¼ê±°ë¡œ ë‘ ì„ ìˆ˜ì˜ í¼í¬ë¨¼ìŠ¤ë¥¼ ë¹„êµí•˜ë¼.\n"
                       "í—ˆìœ„ ì¶”ì • ì—†ì´ ìˆ˜ì¹˜ ê¸°ë°˜ìœ¼ë¡œë§Œ ë¹„êµí•˜ê³ , ë°ì´í„° ë¶€ì¡± ì‹œ 'ì •ë³´ ë¶€ì¡±'ì´ë¼ê³  ë°í˜€ë¼.\n"
                       "ì¶œë ¥ì€ ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ í™œìš©í•˜ë¼."),
            ("human", "ì§ˆë¬¸: {q}\n\n---\nCONTEXT_JSON:\n{ctx_json}")
        ])
        return llm, (prompt | llm | parser)

    # ----------------------------------------------------
    # 2) íƒ€ì„ë¼ì¸ ìš”ì•½ (timeline)
    # ----------------------------------------------------
    if mode == "timeline":
        prompt = ChatPromptTemplate.from_messages([
            ("system", "ë„ˆëŠ” ì¶•êµ¬ ê²½ê¸° íƒ€ì„ë¼ì¸ ë¶„ì„ ì „ë¬¸ê°€ë‹¤.\n"
                       "JSON ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³¨, ê²½ê³ , êµì²´ ë“±ì˜ ì£¼ìš” ì´ë²¤íŠ¸ë¥¼ **ì‹œê°„ìˆœ**ìœ¼ë¡œ ìš”ì•½í•˜ë¼.\n"
                       "ëª¨ë“  ì‹œê°„ì€ ë¶„ ë‹¨ìœ„ë¡œ í‘œì‹œí•˜ê³ , ë°ì´í„°ê°€ ì—†ìœ¼ë©´ 'ì •ë³´ ì—†ìŒ'ì´ë¼ê³  ë°í˜€ë¼."),
            ("human", "ì§ˆë¬¸: {q}\n\n---\nCONTEXT_JSON:\n{ctx_json}")
        ])
        return llm, (prompt | llm | parser)

    # ----------------------------------------------------
    # 3) ìŠ¹íŒ¨ ì›ì¸ ë¶„ì„ (why)
    # ----------------------------------------------------
    if mode == "why":
        prompt = ChatPromptTemplate.from_messages([
            ("system", "ë„ˆëŠ” ì¶•êµ¬ ê²½ê¸°ì˜ ìŠ¹íŒ¨ ì›ì¸ì„ ë¶„ì„í•˜ëŠ” ì „ìˆ  ì½”ì¹˜ë‹¤.\n"
                       "ì£¼ì–´ì§„ JSON ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ì›ì¸ â†’ ì˜í–¥ â†’ ëŒ€ì•ˆ' êµ¬ì¡°ë¡œ ì‘ì„±í•˜ë¼.\n"
                       "ì¶”ì • ì—†ì´, ìˆ˜ì¹˜ì™€ í†µê³„ì— ê¸°ë°˜í•´ ì„¤ëª…í•˜ë¼."),
            ("human", "ì§ˆë¬¸: {q}\n\n---\nCONTEXT_JSON:\n{ctx_json}")
        ])
        return llm, (prompt | llm | parser)

    # ----------------------------------------------------
    # 4) ì „ìˆ  ë¶„ì„ (tactical)
    # ----------------------------------------------------
    if mode == "tactical":
        prompt = ChatPromptTemplate.from_messages([
            ("system", "ë„ˆëŠ” ì¶•êµ¬ ì „ìˆ  ë¶„ì„ ì „ë¬¸ê°€ë‹¤.\n"
                       "í¬ë©”ì´ì…˜, ë¼ì¸ ê°„ê²©, í”„ë ˆì‹±, ë¹Œë“œì—…, ì „í™˜ ì „ìˆ  ë“± ì£¼ìš” ì „ìˆ  ìš”ì†Œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ\n"
                       "JSON ë°ì´í„°ë¥¼ ë¶„ì„í•˜ë¼.\n"
                       "ëª¨í˜¸í•œ í•´ì„ì€ í”¼í•˜ê³  ë°˜ë“œì‹œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª…í•˜ë¼."),
            ("human", "ì§ˆë¬¸: {q}\n\n---\nCONTEXT_JSON:\n{ctx_json}")
        ])
        return llm, (prompt | llm | parser)

    # ----------------------------------------------------
    # 5) ê¸°ë³¸ freeform ë³´ê³ ì„œ
    # ----------------------------------------------------
    outline_llm = ChatOpenAI(model=model_name, temperature=0.2, max_tokens=256)
    outline_prompt = ChatPromptTemplate.from_messages([
        ("system", "ì£¼ì–´ì§„ ì§ˆë¬¸ê³¼ JSON ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ë³´ê³ ì„œ ì„¹ì…˜ ì œëª©ì„ "
                   "3~6ê°œ ì •ë„ JSON ë°°ì—´ë¡œ ì œì•ˆí•˜ë¼.\nì¶”ì¸¡ ì—†ì´ ì‹¤ì œ ê°€ëŠ¥í•œ ë‚´ìš©ë§Œ ì‘ì„±í•  ê²ƒ."),
        ("human", "ì§ˆë¬¸: {q}\n---\nCONTEXT_JSON:\n{ctx_json}")
    ])
    try:
        raw = (outline_prompt | outline_llm | parser).invoke({"q": q, "ctx_json": full_ctx_json}).strip()
        sections = json.loads(raw)
        if not isinstance(sections, list) or not sections:
            sections = ["ìš”ì•½", "í•µì‹¬ í¬ì¸íŠ¸", "ì„¸ë¶€ ë¶„ì„", "ë‹¤ìŒ ê²½ê¸° ì „ë§"]
    except Exception:
        sections = ["ìš”ì•½", "í•µì‹¬ í¬ì¸íŠ¸", "ì„¸ë¶€ ë¶„ì„", "ë‹¤ìŒ ê²½ê¸° ì „ë§"]

    section_lines = "\n".join(f"- {s}" for s in sections)
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ë„ˆëŠ” ì¶•êµ¬ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ë‹¤. ì•„ë˜ ì„¹ì…˜ ê³„íšì— ë”°ë¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ë¼.\n"
                   "ê° ì„¹ì…˜ì€ '## ì„¹ì…˜ëª…'ìœ¼ë¡œ ì‹œì‘í•˜ë©°, ë°ì´í„° ê¸°ë°˜ ì„¤ëª…ê³¼ í‘œ/ë¦¬ìŠ¤íŠ¸ë¥¼ í™œìš©í•˜ë¼.\n"
                   "í—ˆìœ„ ì¶”ì • ê¸ˆì§€. ë°ì´í„° ë¶€ì¡± ì‹œ 'ë°ì´í„° ë¶€ì¡±'ì´ë¼ê³  ëª…ì‹œí•  ê²ƒ."),
        ("human",
         "ì§ˆë¬¸: {q}\n\n---\nCONTEXT_JSON:\n{ctx_json}\n\n"
         "ì„¹ì…˜ ê³„íš:\n{sections}\n")
    ])
    chain = prompt | llm | parser
    return llm, lambda vars: chain.invoke({"q": q, "ctx_json": full_ctx_json, "sections": section_lines})


# === ADD: í’€ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (í‘œì‹œ X, LLM ì „ìš©) ===
def _build_full_context_json(fixture_id: str, matches_state: list) -> str:
    import json
    # ë©”íƒ€ ì°¾ê¸°: ì—†ìœ¼ë©´ None
    meta = None
    for m in matches_state or []:
        if str(m.get("match_id")) == str(fixture_id):
            meta = m; break

    # í•„ìˆ˜: ì„ ìˆ˜ ìŠ¤íƒ¯ + íŒ€ì§‘ê³„/íƒ€ì„ë¼ì¸/ë¼ì¸ì—…
    try: rows, _raw_players = analysis.fetch_player_stats_official(str(fixture_id)) # raw_playresëŠ” json ì›ë³¸
    except Exception: rows = []
    try: tstats = analysis.fetch_team_match_stats_official(str(fixture_id))
    except Exception: tstats = []
    try: events = analysis.fetch_fixture_events_official(str(fixture_id))
    except Exception: events = []
    try: lineups = analysis.fetch_fixture_lineups_official(str(fixture_id))
    except Exception: lineups = []

    # ì‹œì¦Œ/ë¶€ìƒ(ë©”íƒ€ ìˆìœ¼ë©´ í™ˆ/ì›ì • ëª¨ë‘)
    home_season = away_season = {}
    inj_h = inj_a = []
    try:
        if meta and meta.get("league_id") and meta.get("season") and meta.get("home_id") and meta.get("away_id"):
            lid = int(meta["league_id"]); ssn = int(meta["season"])
            hid = int(meta["home_id"]);  aid = int(meta["away_id"])
            try: home_season = analysis.fetch_team_season_stats_official(hid, lid, ssn) or {}
            except Exception: pass
            try: away_season = analysis.fetch_team_season_stats_official(aid, lid, ssn) or {}
            except Exception: pass
            try: inj_h = analysis.fetch_injuries_official(hid, lid, ssn) or []
            except Exception: pass
            try: inj_a = analysis.fetch_injuries_official(aid, lid, ssn) or []
            except Exception: pass
    except Exception:
        pass

    bundle = {
        "meta": {
            "league_id": meta.get("league_id") if meta else None,
            "season": meta.get("season") if meta else None,
            "fixture_id": fixture_id,
            "kickoff_local": meta.get("kickoff_local") if meta else None,
            "home": {"id": meta.get("home_id") if meta else None, "name": meta.get("home") if meta else None},
            "away": {"id": meta.get("away_id") if meta else None, "name": meta.get("away") if meta else None},
            "status": meta.get("status") if meta else None,
        },
        "players": rows,                 # â† ì„ ìˆ˜ë³„ stat.* ì „ë¶€
        "teams_match_stats": tstats,     # â† fixtures/statistics
        "events": events,                # â† fixtures/events
        "lineups": lineups,              # â† fixtures/lineups
        "season_summaries": {"home": home_season, "away": away_season},
        "injuries": {"home": inj_h, "away": inj_a},
    }

    # ë¡œê·¸íŒŒì¼ì— ë‚¨ê¹€
    try:
        log_path = Path(__file__).parent / f"context_bundle_{fixture_id}.json"
        with open(log_path, "w", encoding="utf-8") as f:
            json.dump(bundle, f, ensure_ascii=False, indent=2)
        print(f"[log] context bundle saved: {log_path}")
    except Exception as e:
        print(f"[log] failed to save context bundle: {e}")

    return json.dumps(bundle, ensure_ascii=False, separators=(",", ":"))

# === ADD: ì§ˆë¬¸ â†’ (ì „ ë°ì´í„° ìë™ìˆ˜ì§‘) â†’ LLM ë‹µë³€ (UIì—” ë‹µë§Œ ë³´ì—¬ì¤Œ) ===
def ui_analyze_match_full_auto(question: str, fixture_id: str, matches_state: list):
    # fixture_idê°€ ë¹„ì–´ìˆìœ¼ë©´ ëª©ë¡ì˜ ì²« ê²½ê¸° ìë™ ì„ íƒ
    if not fixture_id and (matches_state or []):
        fixture_id = str((matches_state[0] or {}).get("match_id") or "")
    if not fixture_id:
        return "<em>ê²½ê¸°ë¥¼ ë¨¼ì € ë¶ˆëŸ¬ì˜¤ì„¸ìš”.</em>"

    ctx_json = _build_full_context_json(fixture_id, matches_state)

    # ì»¨í…ìŠ¤íŠ¸ëŠ” 'ì „ë¶€' ì‚¬ìš©. ë„ˆë¬´ í´ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ê°„ë‹¨ ì••ì¶•(ë¬¸ì ê¸¸ì´ ê¸°ì¤€)
    def _approx_tokens(s: str) -> int: return max(1, len(s)//4)
    budget = 120000  # ëª¨ë¸ í† í° í•œë„ì— ë§ì¶° ì¡°ì ˆ(ì˜ˆ: 128k ëª¨ë¸)
    if _approx_tokens(ctx_json) > budget:
        # í° ì„¹ì…˜(íŠ¹íˆ players, events)ë¶€í„° ì•ë¶€ë¶„ë§Œ ë‚¨ê¹€
        import json as _json
        try:
            data = _json.loads(ctx_json)
            order = ["meta","lineups","teams_match_stats","players","events","season_summaries","injuries"]
            slim = {}
            for key in order:
                slim[key] = data.get(key)
                s = _json.dumps(slim, ensure_ascii=False, separators=(",", ":"))
                if _approx_tokens(s) > budget and key in {"players","events"} and isinstance(slim[key], list):
                    slim[key] = slim[key][: max(1, len(slim[key])//2)]
            ctx_json = _json.dumps(slim, ensure_ascii=False, separators=(",", ":"))
        except Exception:
            pass


    mode = _detect_stats_mode(question)

    # ëª¨ë“œë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
    llm, chain = _build_prompt_for_mode(mode, question, ctx_json, max_tokens=2000)

    try:
        if callable(chain):
            return chain({"q": question, "ctx_json": ctx_json})
        return chain.invoke({"q": question, "ctx_json": ctx_json})
    except Exception as e:
        return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"

    # LLM ì²´ì¸(ê°„ë‹¨): ì‹œìŠ¤í…œ+íœ´ë¨¼
    # prompt = ChatPromptTemplate.from_messages([
    #     ("system",
    #      "ë„ˆëŠ” ì¶•êµ¬ ê²½ê¸° ë¶„ì„ ì „ë¬¸ê°€ë‹¤. "
    #      "ë°˜ë“œì‹œ ì œê³µëœ JSON ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•´ì•¼ í•œë‹¤. "
    #      "ëª¨ë“  ì£¼ì¥ê³¼ ì„¤ëª…ì€ ë°˜ë“œì‹œ ìˆ˜ì¹˜ì™€ ë°ì´í„°ì— ê·¼ê±°í•´ì•¼ í•œë‹¤. "
    #      "ì¶”ì¸¡ì´ë‚˜ ì™¸ë¶€ ì§€ì‹ì„ ì¶”ê°€í•˜ì§€ ë§ê³ , ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë¼."),
    #     ("human", "ì§ˆë¬¸: {q}\n\n---\nCONTEXT_JSON:\n{ctx_json}")
    # ])
    # chain = prompt | llm | parser
    # try:
    #     return chain.invoke({"q": question, "ctx_json": ctx_json})
    # except Exception as e:
    #     return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"

"""
ì—¬ê¸°ê¹Œì§€ ê²½ê¸° ë¶„ì„ì—ì„œ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜
"""

try:
    # í”„ë¡œì íŠ¸ì— ë”°ë¼ ìœ„ì¹˜ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ë‘ ê²½ë¡œ ëª¨ë‘ ì‹œë„
    from langchain_community.retrievers import BM25Retriever
except Exception:
    from langchain.retrievers import BM25Retriever  # fallback

from langchain_core.documents import Document

# (ì˜µì…˜) í¬ë¡œìŠ¤ ì¸ì½”ë” â€” ì—†ìœ¼ë©´ ìë™ í´ë°±
try:
    from sentence_transformers import CrossEncoder
except Exception:
    CrossEncoder = None

load_dotenv()
bm25_all_docs = []

#time ë¬¸ìì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜
def _parse_meta_time(s):
    """metadata['time'] ë¬¸ìì—´ì„ datetimeìœ¼ë¡œ íŒŒì‹± (ì—¬ëŸ¬ í¬ë§· í—ˆìš©)"""
    if not s:
        return None
    s = str(s).strip()
    fmts = [
        "%Y-%m-%d %H:%M:%S",   # 2025-06-25 20:05:00
        "%Y-%m-%d",            # 2025-06-25
        "%Y/%m/%d",            # 2025/06/25
        "%Y.%m.%d",            # 2025.06.25
        "%Y-%m-%dT%H:%M:%SZ",  # 2025-06-25T20:05:00Z
        "%Y-%m-%dT%H:%M:%S%z"  # 2025-06-25T20:05:00+0000
    ]
    zfix = s.replace("Z", "+0000") if s.endswith("Z") else s
    for fmt in fmts:
        try:
            if fmt.endswith("%z"):
                return dt.strptime(zfix, fmt)
            return dt.strptime(s, fmt)
        except Exception:
            continue
    return None

# ë‰´ìŠ¤ì˜ ë‚ ì§œë¥¼ ê³ ë ¤í•´ ìµœì‹  ë‰´ìŠ¤ê°€ ìœ„ë¡œ ì˜¤ê²Œ ì¬ì •ë ¬ (ì§€ê¸ˆì€ ë‚ ì§œ ë¯¸ì§€ì • ì‹œì—ë§Œ ì ìš©)
def freshness_reorder(docs, half_life_days=10, weight=0.6, hard_days=None):
    """RRF ê²°ê³¼ë¥¼ 'ìµœê·¼ì¼ìˆ˜ë¡ ì‚´ì§ ê°€ì 'ìœ¼ë¡œ ì¬ì •ë ¬. ë‚ ì§œ ì—†ìœ¼ë©´ ê°€ì  0."""
    if not docs:
        return docs
    now = dt.now()
    scored = []
    for idx, d in enumerate(docs):
        t = _parse_meta_time((d.metadata or {}).get("time"))
        if t:
            age_days = max(0.0, (now - t).total_seconds() / 86400.0) # ë©°ì¹  ì „ ë¬¸ì„œì¸ì§€ ê³„ì‚° 1ì¼ = 86400ì´ˆ
            if hard_days is not None and age_days > float(hard_days): # ë„ˆë¬´ ì˜¤ë˜ë˜ë©´ ì œì™¸(í˜„ì¬ ë°˜ì˜ x)
                ConnectionRefusedError
            boost = math.exp(-age_days / float(half_life_days))  # 0~1 ìµœì‹  ë¬¸ì„œ: 1
        else:
            boost = 0.0
        base = 1.0 / (1.0 + idx)  # ìƒìœ„ì¼ìˆ˜ë¡ í¼, ì›ë˜ ìƒìœ„ì— ìˆë˜ ë¬¸ì„œ
        scored.append((base * (1.0 + float(weight) * boost), idx, d)) # boostì™€ ê°€ì¤‘ì¹˜ ê³„ì‚°
    scored.sort(key=lambda x: (-x[0], x[1])) # ì ìˆ˜ ë†’ì€ ìˆœ, ê°™ì„ ê²½ìš° ì›ë˜ ìˆœì„œ
    return [d for _, _, d in scored]

# ì…ë ¥ëœ ë‚ ì§œë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
def _parse_date_input(s):
    """UI ì…ë ¥ YYYY-MM-DD / YYYY/MM/DD / YYYY.MM.DD â†’ datetime.date"""
    if not s:
        return None
    s = s.strip()
    m = re.match(r"^\s*(\d{4})[-/.](\d{1,2})[-/.](\d{1,2})\s*$", s)
    if not m:
        return None
    y, mth, d = map(int, m.groups())
    try:
        return dt(y, mth, d)
    except Exception:
        return None

# í•˜ë£¨ì˜ ë§ˆì§€ë§‰ìœ¼ë¡œ ì„¤ì •
def _end_of_day(d):
    return d.replace(hour=23, minute=59, second=59, microsecond=999999)

# ë‚ ì§œ ë²”ìœ„ì˜ ë‰´ìŠ¤ë¥¼ í•„í„°ë§
def filter_docs_by_date(docs, start_dt, end_dt):
    """ë¬¸ì„œì˜ metadata['time']ì´ [start_dt, end_dt] ë²”ìœ„ì¸ ê²ƒë§Œ"""
    picked = []
    for d in docs or []:
        t = _parse_meta_time((d.metadata or {}).get("time"))
        if t and start_dt <= t <= end_dt:
            picked.append(d)
    return picked

# ë‚ ì§œ ë²”ìœ„ì˜ ë‰´ìŠ¤ë¥¼ ì•ìœ¼ë¡œ ì˜®ê¹€ (ì²´í¬ ë°•ìŠ¤ ì•ˆí–ˆì„ ë•Œ)
def prefer_date_range_first(docs, start_dt, end_dt):
    """í•´ë‹¹ ë²”ìœ„ ë¬¸ì„œë¥¼ ì•ìœ¼ë¡œ(ê¸°ì¡´ ìƒëŒ€ ìˆœì„œëŠ” ìœ ì§€)"""
    in_range, out_range = [], []
    for idx, d in enumerate(docs or []):
        t = _parse_meta_time((d.metadata or {}).get("time"))
        (in_range if (t and start_dt <= t <= end_dt) else out_range).append((idx, d))
    in_range.sort(key=lambda x: x[0])
    out_range.sort(key=lambda x: x[0])
    return [d for _, d in (in_range + out_range)]

# -------------------------
# ì„¤ì • / ì „ì—­
# -------------------------
# LLM & ì„ë² ë”© (ì›ë˜ ì„¤ì • ì¡´ì¤‘)
llm = ChatOpenAI(model="gpt-4o-mini")
hf_embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-m3")
persist_directory = "./news_chroma_db"

# ì„¤ì • íŒŒì¼ ë¡œë“œ
try:
    with open("config.json", "r", encoding="utf-8") as f:
        config = json.load(f)
except Exception:
    config = {}

system_message = config.get(
    "system_message"
)
human_message_template = config.get(
    "human_message_template"
)
# íŒ€ ì´ë¦„ í•„í„°ë§
translation_dict = config.get("translation_dict", {})

prompt_template = ChatPromptTemplate.from_messages([
    ("system", system_message),
    ("human", human_message_template),
])
parser = StrOutputParser()

# ì²´ì¸/ë¦¬íŠ¸ë¦¬ë²„ ì „ì—­
rag_chain = None
hybrid_retriever = None
vector_retriever = None
context_chain = None

# BM25/ì¬ë­ì»¤ ì „ì—­
bm25_global = None
bm25_doc_count = 0
reranker = None


# -------------------------
# ìœ í‹¸
# -------------------------

# ë‹¨ì–´ ì‚¬ì „ì— ìˆëŠ” íŒ€ì˜ í•œêµ­ ì´ë¦„ì„ ì˜ì–´ë¡œ ë³€ê²½
def translate_query(query: str, dictionary: dict) -> str:
    """ê°„ë‹¨í•œ ë‹¨ì–´ ê²½ê³„ ì¹˜í™˜(ì‚¬ì „ ì—†ìœ¼ë©´ ì›ë¬¸ ê·¸ëŒ€ë¡œ)"""
    if not query or not dictionary:
        return query
    for kor, eng in dictionary.items():
        query = query.replace(kor, eng)
    return query

# ì—¬ëŸ¬ ê°œì˜ ë¦¬ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ê°ê°ì˜ ë“±ìˆ˜ì— ëŒ€í•´ ê³„ì‚°ì— ë”í•œ ì´ ì ìˆ˜ë¡œ ì •ë ¬
def rrf_fuse(result_lists, k=36, C=60):
    """Reciprocal Rank Fusion: ì—¬ëŸ¬ ë¦¬ìŠ¤íŠ¸ì˜ ë“±ìˆ˜ë¥¼ í•©ì‚°í•´ ìƒìœ„ kê°œ ì„ íƒ"""
    from collections import defaultdict
    scores, pick = defaultdict(float), {}
    for results in result_lists: 
        for rank, d in enumerate(results):
            key = d.page_content
            scores[key] += 1.0 / (C + rank + 1)
            pick.setdefault(key, d)
    merged = [pick[key] for key, _ in sorted(scores.items(), key=lambda x: x[1], reverse=True)]
    return merged[:k]

# í•œêµ­ì–´ ì¿¼ë¦¬ë¥¼ ì˜ì–´ë¡œ ë³€í™˜
def gpt_translate_korean_to_english(query: str, model="gpt-4o-mini") -> str:
    prompt = ChatPromptTemplate.from_messages([
        ("system", "Translate the following Korean football question into English for use in a document search engine. Be concise."),
        ("human", "{q}")
    ])
    chain = prompt | ChatOpenAI(model=model, temperature=0) | StrOutputParser()
    return chain.invoke({"q": query})

# bm25 ê²€ìƒ‰ê¸° ìƒì„±, 30ê°œ
def build_global_bm25():
    """ì „ ì½”í¼ìŠ¤ BM25 ì¸ë±ìŠ¤ ì¬ìƒì„± (idsë¥¼ includeë¡œ ìš”ì²­í•˜ì§€ ì•ŠìŒ)"""
    global bm25_global, bm25_doc_count
    db = Chroma(
        persist_directory=str((Path(__file__).resolve().parent / "news_chroma_db")),
        embedding_function=hf_embeddings,
        collection_name="news_collection",
    )
    raw = db.get(include=["documents", "metadatas"])  # âœ… ids ê¸ˆì§€
    all_docs = [
        Document(page_content=c, metadata=m)
        for c, m in zip(raw.get("documents", []), raw.get("metadatas", []))
        if c
    ]
    bm25 = BM25Retriever.from_documents(all_docs)
    bm25.k = int(config.get("bm25_k", 30))  # íšŒìˆ˜ í­ ì‚´ì§ ë„“í˜
    bm25_global = bm25
    global bm25_all_docs
    bm25_all_docs = all_docs
    # ì•ˆì „í•œ ë¬¸ì„œ ìˆ˜ í™•ì¸
    try:
        bm25_doc_count = db._collection.count()
    except Exception:
        bm25_doc_count = len(raw.get("documents", []))

    print(f"[bm25] rebuilt: docs={bm25_doc_count}, k={bm25_global.k}")
    return bm25_doc_count

# dbë¬¸ì„œ ìˆ˜ê°€ ë‹¬ë¼ì§€ë©´ build_global_bm25ë¥¼ í˜¸ì¶œí•˜ì—¬ ê°±ì‹ 
def refresh_bm25_if_stale():
    """DB ë¬¸ì„œ ìˆ˜ê°€ ë³€í•˜ë©´ BM25ë¥¼ ìë™ ê°±ì‹ """
    from langchain_community.vectorstores import Chroma
    from pathlib import Path
    global bm25_doc_count, bm25_global, hf_embeddings

    try:
        db = Chroma(
            persist_directory=str((Path(__file__).resolve().parent / "news_chroma_db")),
            embedding_function=hf_embeddings,
            collection_name="news_collection",
        )
        # âœ… ì ˆëŒ€ db.get(include=["ids"]) ì“°ì§€ ë§ ê²ƒ
        cnt = db._collection.count()
        if cnt != bm25_doc_count or bm25_global is None:
            build_global_bm25()
    except Exception as e:
        print(f"[bm25] refresh failed: {e}")

# í¬ë¡œìŠ¤ ì¸ì½”ë” ì„¤ì •
def init_reranker_from_config(cfg: dict):
    """í¬ë¡œìŠ¤ ì¸ì½”ë” ì´ˆê¸°í™”(ì˜µì…˜) â€” ì‹¤íŒ¨í•´ë„ ì„œë¹„ìŠ¤ ê³„ì†"""
    global reranker
    if not cfg.get("use_reranker", True):
        return
    if CrossEncoder is None:
        print("[reranker] sentence-transformers ë¯¸ì„¤ì¹˜ â†’ ê±´ë„ˆëœ€")
        return
    model = cfg.get("reranker_model", "BAAI/bge-reranker-base")
    max_len = int(cfg.get("reranker_max_length", 512))
    try:
        reranker = CrossEncoder(model, max_length=max_len)
        print(f"[reranker] loaded: {model}")
    except Exception as e:
        reranker = None
        print(f"[reranker] load failed: {e}")

# í¬ë¡œìŠ¤ ì¸ì½”ë”ë¡œ ì ìˆ˜ë¥¼ ë§¤ê²¨ ì¬ì •ë ¬
def rerank_with_cross_encoder(query: str, docs, top_n=12, batch_size=16):
    """í¬ë¡œìŠ¤ ì¸ì½”ë” ì¬ë­í¬ (ë¹„í™œì„±/ì‹¤íŒ¨ ì‹œ candidates ì•ì—ì„œ ìë¦„)"""
    if not docs:
        return []
    if reranker is None:
        return docs[:top_n]
    pairs = [[query, d.page_content] for d in docs]
    try:
        scores = reranker.predict(pairs, batch_size=batch_size, show_progress_bar=False)
    except Exception:
        return docs[:top_n]
    ranked = sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)
    return [d for d, _ in ranked[:top_n]]


# -------------------------
# ì²´ì¸ êµ¬ì„±
# -------------------------
# ì´ˆê¸° ì„¸íŒ…
def create_rag_chain():
    global persist_directory, hf_embeddings, prompt_template, llm, parser
    global rag_chain, vector_retriever, context_chain, hybrid_retriever

    # ë²¡í„° DB
    db = Chroma(
        persist_directory=str((Path(__file__).resolve().parent / "news_chroma_db")),
        embedding_function=hf_embeddings,
        collection_name="news_collection",  # ì¤‘ìš”
    )

    # ë²¡í„° ë¦¬íŠ¸ë¦¬ë²„: MMR(ë‹¤ì–‘ì„±) ë˜ëŠ” ê¸°ë³¸
    if config.get("use_mmr", True):
        vector_retriever = db.as_retriever(
            search_type="mmr",  # ì¤‘ë³µ ì ê²Œ
            search_kwargs={
                "k": int(config.get("mmr_k", 20)),         # ìµœì¢… ì¶”ì¶œ ìˆ˜ (RRF í›„ë³´ë¡œ)
                "fetch_k": int(config.get("mmr_fetch_k", 80)), # 80ê°œ ë½‘ê³  ê·¸ì¤‘ì—ì„œ ì„ íƒ
                "lambda_mult": float(config.get("mmr_lambda", 0.7)), # ìœ ì‚¬ë„ì— ê°€ê¹ê²Œ
            },
        )
    else:
        vector_retriever = db.as_retriever(search_kwargs={"k": int(config.get("k", 20))})

    # ì „ì½”í¼ìŠ¤ BM25 êµ¬ì¶•/ì´ˆê¸°í™”
    build_global_bm25()

    # RAG íŒŒì´í”„ë¼ì¸
    rag_chain = {
        "context": RunnablePassthrough(),
        "input": RunnablePassthrough()
    } | prompt_template | llm | parser

    # (ì˜µì…˜) ì¬ë­ì»¤ ì¤€ë¹„
    init_reranker_from_config(config)

    # ìƒíƒœ ë©”ì‹œì§€
    try:
        count = db._collection.count()
    except Exception:
        count = 0
    return f"ì¤€ë¹„ ì™„ë£Œ / ë¬¸ì„œ ìˆ˜: {count}"

# ìµœì¢… ê²°ê³¼ë¡œ ë½‘íŒ ë‰´ìŠ¤ì¤‘ì—ì„œ ì¤‘ë³µë˜ì§€ ì•Šê²Œ ë§í¬ë¥¼ ê°€ì ¸ì˜´
def _build_unique_links(docs, max_items=None):
    if not docs:
        return ""
    seen, urls = set(), []
    items = docs[:max_items] if max_items else docs
    for d in items:
        m = d.metadata or {}
        url = (m.get("url") or "").strip()
        if not url:
            continue
        url2 = url
        if url2 and url2 not in seen:
            seen.add(url2)
            urls.append(url2)
    return "\n".join(urls)

# ê°€ì ¸ì˜¨ ë§í¬ë¥¼ htmlë¡œ ë³´ì´ê²Œ í•¨
def _links_collapsible_html(docs, max_items_show=5):
    links_str = _build_unique_links(docs, max_items=200)
    if not links_str:
        return ""

    # â˜… ì—¬ê¸°ì„œ ë°˜ë“œì‹œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì•¼ í•¨
    links = [u for u in links_str.split("\n") if u]

    def _a(u: str) -> str:
        # <li><a href= > í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        u2 = (u or "").strip()
        p = urlparse(u2)
        shown = (p.netloc or "") + (p.path or "")
        if len(shown) > 48:
            shown = shown[:47] + "â€¦"
        return (
            f'<li><a href="{html.escape(u2)}" '
            f'target="_blank" rel="noopener noreferrer">{html.escape(shown)}</a></li>'
        )

    head = links[:max_items_show]
    tail = links[max_items_show:]
    head_html = "".join(_a(u) for u in head)
    if not tail:
        return f"<ul>{head_html}</ul>"

    tail_html = "".join(_a(u) for u in tail)
    return (
        f"<ul>{head_html}</ul>"
        f'<details><summary>ë§í¬ {len(tail)}ê°œ ë”ë³´ê¸°</summary>'
        f"<ul>{tail_html}</ul>"
        f"</details>"
    )


try:
    from zoneinfo import ZoneInfo
    def _today_kst():
        return datetime.now(ZoneInfo("Asia/Seoul")).date()
except Exception:
    def _today_kst():  # fallback
        return datetime.utcnow().date()


def _parse_ymd(s: str | None) -> date | None:
    if not s:
        return None
    # flatpickrì˜ stringì€ ë³´í†µ YYYY-MM-DD
    try:
        return datetime.strptime(s, "%Y-%m-%d").date()
    except ValueError:
        # í˜¹ì‹œ ISO ë³€í˜• ë“¤ì–´ì˜¬ ë•Œ ëŒ€ë¹„
        try:
            return datetime.fromisoformat(s).date()
        except Exception:
            return None

# ì‹œì‘ì¼ ë³€ê²½ ì‹œ: ë¯¸ë˜ ë‚ ì§œ ê¸ˆì§€(ê²½ê³  + ì‹œì‘ì¼ ë¹„ì›€)
def on_start_change(start_s: str | None, end_s: str | None):
    ds = _parse_ymd(start_s)
    today = _today_kst()
    if ds and ds > today:
        gr.Warning(f"ì‹œì‘ì¼ì€ ì˜¤ëŠ˜({_today_kst().strftime('%Y-%m-%d')})ì„ ë„˜ê¸¸ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œì‘ì¼ì„ ë¹„ì› ìŠµë‹ˆë‹¤.")
        return None
    return start_s  # ì •ìƒì´ë©´ ìœ ì§€

# ì¢…ë£Œì¼ ë³€ê²½ ì‹œ: (1) ë¯¸ë˜ ë‚ ì§œ ê¸ˆì§€ (2) ì‹œì‘ì¼ë³´ë‹¤ ë¹ ë¥´ë©´ ê¸ˆì§€ â€” ë‘˜ ë‹¤ ê²½ê³  + ì¢…ë£Œì¼ ë¹„ì›€
def on_end_change(start_s: str | None, end_s: str | None):
    ds, de = _parse_ymd(start_s), _parse_ymd(end_s)
    today = _today_kst()
    if de and de > today:
        gr.Warning(f"ì¢…ë£Œì¼ì€ ì˜¤ëŠ˜({_today_kst().strftime('%Y-%m-%d')})ì„ ë„˜ê¸¸ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œì¼ì„ ë¹„ì› ìŠµë‹ˆë‹¤.")
        return None
    if ds and de and de < ds:
        gr.Warning("ì¢…ë£Œì¼ì´ ì‹œì‘ì¼ë³´ë‹¤ ë¹ ë¦…ë‹ˆë‹¤. ì¢…ë£Œì¼ì„ ë¹„ì› ìŠµë‹ˆë‹¤.")
        return None
    return end_s  # ì •ìƒì´ë©´ ìœ ì§€

# -------------------------
# ì§ˆì˜ ì²˜ë¦¬
# -------------------------
def ask_question(question: str, start_date: str | None = None, end_date: str | None = None, hard_only: bool = False):

    # BM25 ìµœì‹ í™”
    refresh_bm25_if_stale()

    if vector_retriever is None or rag_chain is None:
        return ("âŒ ì‹œìŠ¤í…œì´ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", "")

    try:
        # 0) UI ë‚ ì§œ ì…ë ¥ íŒŒì‹±
        sd = _parse_date_input(start_date)
        ed = _parse_date_input(end_date)
        if sd and not ed: ed = sd
        if ed and not sd: sd = ed
        if sd and ed: ed = _end_of_day(ed)

        # 1) ì§ˆì˜ ì „ì²˜ë¦¬
        q = translate_query(question, translation_dict).lower()

        # 2) ë¦¬íŠ¸ë¦¬ë²Œ (ë²¡í„° + BM25)
        vector_docs = vector_retriever.invoke(q)
        bm_docs = bm25_global.invoke(gpt_translate_korean_to_english(q)) if bm25_global is not None else []

        if not vector_docs and not bm_docs:
            return ("ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. links.jsonì„ ì—…ë°ì´íŠ¸í•˜ê³  ì„ë² ë”©ì„ ë‹¤ì‹œ ìƒì„±í•´ì£¼ì„¸ìš”.", "")

        # 3) (ë‚ ì§œ í›„ë³´ ë³´ê°•) ë‚ ì§œ ì§€ì • ì‹œ, ì „ ì½”í¼ìŠ¤ì—ì„œ í•´ë‹¹ ë‚ ì§œ ë¬¸ì„œ ì¶”ê°€
        # bm25_all_docs: ì „ì²´ ë¬¸ì„œ ëª©ë¡ (Chromaì— ì €ì¥ëœ ëª¨ë“  ë¬¸ì„œì˜ ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„°)
        result_lists = [vector_docs, bm_docs] # ê²€ìƒ‰í•´ì„œ ë‚˜ì˜¨ ê²°ê³¼ë¥¼ í•©ì¹¨
        if sd and ed and bm25_all_docs:
            date_docs_full = filter_docs_by_date(bm25_all_docs, sd, ed)
            if date_docs_full:
                result_lists.append(date_docs_full) # ë‚ ì§œ ì‚¬ì´ì— ìˆëŠ” ë‰´ìŠ¤ë¥¼ ì¶”ê°€

        # 4) RRF ìœµí•©
        candidates = rrf_fuse(
            result_lists,
            k=int(config.get("rrf_candidates_k", 36)),
            C=int(config.get("rrf_C", 60)),
        )

        # 5) ë‚ ì§œ í•„í„°/ì •ë ¬
        if sd and ed:
            if hard_only:
                candidates = filter_docs_by_date(candidates, sd, ed)   # í•˜ë“œ ì»·
            else:
                candidates = prefer_date_range_first(candidates, sd, ed)  # ì†Œí”„íŠ¸ ìš°ì„ 
        else:
            # ë‚ ì§œ ë¯¸ì§€ì • ì‹œì—ë§Œ 'í˜„ì¬ ê¸°ì¤€' ì‹ ì„ ë„ ì ìš©
            if config.get("freshness_enable", True):
                candidates = freshness_reorder(
                    candidates,
                    half_life_days=int(config.get("freshness_half_life_days", 10)),
                    weight=float(config.get("freshness_weight", 0.6)),
                    hard_days=int(config.get("freshness_hard_days", 0)) or None,
                )

        # 6) (ì˜µì…˜) ì¬ë­í¬ â†’ ìµœì¢… Nê°œ
        final_n = int(config.get("rrf_k", 12))
        if config.get("use_reranker", True):
            reranker_query = question or q
            final_docs = rerank_with_cross_encoder(
                reranker_query,
                candidates,
                top_n=final_n,
                batch_size=int(config.get("reranker_batch_size", 16)),
            )
        else:
            final_docs = candidates[:final_n]

        # 7) ì»¨í…ìŠ¤íŠ¸ â†’ LLM
        context = "\n\n".join(d.page_content for d in final_docs)
        result = rag_chain.invoke({"context": context, "input": question})

        global last_final_docs
        last_final_docs = final_docs


        links_html = _links_collapsible_html(final_docs, max_items_show=int(config.get("links_head_show", 5)))
        return result, links_html

    except Exception as e:
        return (f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", "")



# === Add: background ingest scheduler ===
import os, sys, time, threading, subprocess
from pathlib import Path

LOCKFILE = Path(__file__).with_name(".ingest.lock")

# ë½íŒŒì¼ ìƒì„±
def _acquire_lock() -> bool:
    try:
        fd = os.open(LOCKFILE, os.O_CREAT | os.O_EXCL | os.O_WRONLY)
        os.write(fd, str(os.getpid()).encode()); os.close(fd)
        return True
    except FileExistsError:
        return False

def _release_lock():
    try: os.remove(LOCKFILE)
    except FileNotFoundError: pass


INGEST_EVERY_MIN = int(os.getenv("INGEST_EVERY_MINUTES", "3"))  # ê¸°ë³¸ 30ë¶„
AUTO_INGEST = os.getenv("AUTO_INGEST", "1") != "0"               # 0ì´ë©´ ë¹„í™œì„±

_ingest_lock = threading.Lock()

def ingest_once():
    if not _acquire_lock():
        print("[ingest] another run in progress; skip.")
        return
    try:
        with _ingest_lock:  # ìŠ¤ë ˆë“œ ì¤‘ë³µ ë°©ì§€
            base = Path(__file__).resolve().parent
            subprocess.run([sys.executable, str(base/"news_delta_anchor.py"), "--batch","10","--max-pages","40"])
            subprocess.run([sys.executable, str(base/"crawling.py")])
            subprocess.run([sys.executable, str(base/"imbedding.py")])
            print("[ingest] done.")
    finally:
        _release_lock()

def _ingest_loop():
    """í”„ë¡œì„¸ìŠ¤ ìƒì¡´ ë™ì•ˆ ì£¼ê¸° ì‹¤í–‰ (ì˜¤ë²„ë© ë°©ì§€)"""
    # ì‹œì‘ ì§í›„ í•œ ë²ˆ ì‹¤í–‰í•˜ê³  ì£¼ê¸°ë¡œ ë°˜ë³µí•˜ê³  ì‹¶ìœ¼ë©´ ë‹¤ìŒ ì¤„ ì£¼ì„ í•´ì œ
    # ingest_once()
    while True:
        started = time.time()
        try:
            ingest_once()
        except Exception as e:
            print(f"[ingest] unexpected error: {e}")
        # ì‹¤í–‰ ì‹œê°„ ê³ ë ¤í•´ ë‹¤ìŒ ì‹¤í–‰ê¹Œì§€ ë‚¨ì€ ì‹œê°„ë§Œí¼ ëŒ€ê¸°
        sleep_s = max(INGEST_EVERY_MIN * 60 - (time.time() - started), 5)
        time.sleep(sleep_s)




# -------------------------
# Gradio UI (ì›í˜• ìœ ì§€)
# -------------------------
with gr.Blocks(
    theme=gr.themes.Soft(),
    css="""
    .card { background:#fff; border:1px solid #eee; border-radius:16px; padding:14px 16px; box-shadow:0 4px 14px rgba(0,0,0,0.06); }
    .chip { display:inline-flex; align-items:center; gap:8px; padding:6px 12px; border-radius:999px; background:#eef6ff; border:1px solid #cfe2ff; font-weight:600; font-size:13px; }
    .fld { font-size:12px; font-weight:700; color:#222; margin-bottom:6px; letter-spacing:.2px; }
    .subtle { color:#666; font-size:12px; margin-top:6px; }
    .pillwrap { display:flex; flex-wrap:wrap; gap:10px; }
    """) as demo:
    with gr.Row():
        btn_news = gr.Button("ğŸ“° ë‰´ìŠ¤ ìš”ì•½", scale=1)
        btn_analysis = gr.Button("âš½ ê²½ê¸° ë¶„ì„", scale=1)

    gr.Markdown("""
    # ğŸ“„ ì¸ê³µì§€ëŠ¥ ì¶•êµ¬ ë‰´ìŠ¤ ì±—ë´‡
    **ì¶•êµ¬ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ AIê°€ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
    """)

    # === í™”ë©´1: ë‰´ìŠ¤ ìš”ì•½ (ì´ˆê¸° í‘œì‹œ) ===
    with gr.Group(visible=True) as news_group:
        with gr.Row():
            with gr.Column(scale=1):
                status_output = gr.Textbox(label="ğŸ“¢ ìƒíƒœ ë©”ì„¸ì§€")
                question_input = gr.Textbox(label="ğŸ’¬ ì§ˆë¬¸ ì…ë ¥", placeholder="ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì ì–´ì£¼ì„¸ìš”.")
                preset = gr.Dropdown(
                    label="ë¹ ë¥¸ ì„ íƒ",
                    choices=["ë‚ ì§œ ì§€ì • ì•ˆí•¨", "ì˜¤ëŠ˜", "ì–´ì œ", "ìµœê·¼ 7ì¼", "ìµœê·¼ 30ì¼", "ì´ë²ˆ ì£¼", "ì´ë²ˆ ë‹¬", "ì§€ë‚œ ë‹¬"],
                    value="ë‚ ì§œ ì§€ì • ì•ˆí•¨"
                )
                start_date_input = Calendar(label="ì‹œì‘ì¼", type="string", value=None)
                end_date_input   = Calendar(label="ì¢…ë£Œì¼", type="string", value=None)
                hard_only_check  = gr.Checkbox(label="ë‚ ì§œ ë²”ìœ„ë§Œ ë³´ê¸°(í•˜ë“œ í•„í„°)", value=False)
                submit_button    = gr.Button("ğŸ¤– ë‹µë³€ ë°›ê¸°")
                answer_output    = gr.Textbox(label="ğŸ“ AI ë‹µë³€")
                links_output     = gr.HTML(label="ê´€ë ¨ ë§í¬")

                # ë³€ê²½ ì‹œ ê²€ì¦: ë°˜í™˜ê°’ìœ¼ë¡œ í•´ë‹¹ ì»´í¬ë„ŒíŠ¸ë¥¼ ì—…ë°ì´íŠ¸
                start_date_input.change(
                    fn=on_start_change,
                    inputs=[start_date_input, end_date_input],
                    outputs=[start_date_input],
                )
                end_date_input.change(
                    fn=on_end_change,
                    inputs=[start_date_input, end_date_input],
                    outputs=[end_date_input],
                )
    # === í™”ë©´2: ê²½ê¸° ë¶„ì„ (ì´ˆê¸° ìˆ¨ê¹€) ===
    with gr.Group(visible=False) as analysis_group:
        gr.Markdown("### âš½ ê²½ê¸° ë¶„ì„")
        gr.Markdown("- í˜„ì¬ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ìˆ˜ì§‘ëœ ë§í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ `ë¶„ì„.py`ì˜ analyze()ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.")

        with gr.Row(elem_classes="card"):
            # (A) ë°ì´í„° ì†ŒìŠ¤ ì¹©
            with gr.Column(scale=1, min_width=180):
                gr.Markdown("<div class='fld'>ë°ì´í„° ì†ŒìŠ¤</div>")
                gr.HTML("<div class='chip'>ğŸ›°ï¸ API-FOOTBALL</div>")
                gr.Markdown("<div class='subtle'>ê³µì‹ API ê¸°ë°˜ ê²½ê¸°/ì„ ìˆ˜ ë°ì´í„°</div>")

            # (B) ë‚ ì§œ ì„ íƒ
            with gr.Column(scale=1, min_width=240):
                gr.Markdown("<div class='fld'>ë‚ ì§œ</div>")
                match_date = Calendar(label="ê²½ê¸°ì¼", type="string", value="")

            # (C) ë¦¬ê·¸ í•„í„° (5ê°œ ì²´í¬ë°•ìŠ¤)
            with gr.Column(scale=3, min_width=420):
                gr.Markdown("<div class='fld'>ë¦¬ê·¸ í•„í„°</div>")
                with gr.Row(elem_classes="pillwrap"):
                    cb_epl     = gr.Checkbox(label="ğŸ´ Premier League", value=True, show_label=False)
                    cb_laliga  = gr.Checkbox(label="ğŸ‡ªğŸ‡¸ LaLiga",          value=True, show_label=False)
                    cb_seriea  = gr.Checkbox(label="ğŸ‡®ğŸ‡¹ Serie A",         value=True, show_label=False)
                    cb_bundes  = gr.Checkbox(label="ğŸ‡©ğŸ‡ª Bundesliga",      value=True, show_label=False)
                    cb_ligue1  = gr.Checkbox(label="ğŸ‡«ğŸ‡· Ligue 1",         value=True, show_label=False)
                gr.Markdown("<div class='subtle'>ì²´í¬ í•´ì œëœ ë¦¬ê·¸ëŠ” ëª©ë¡ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.</div>")

            # (D) ì‹¤í–‰ ë²„íŠ¼
            with gr.Column(scale=1, min_width=160):
                gr.Markdown("<div class='fld'>&nbsp;</div>")
                load_btn = gr.Button("ğŸ” ê²½ê¸° ë¶ˆëŸ¬ì˜¤ê¸°", variant="primary")


        matches_html = gr.HTML(label="ê²½ê¸° ëª©ë¡")
        match_select = gr.Dropdown(label="ê²½ê¸° ì„ íƒ(ì„ ìˆ˜ ìŠ¤íƒ¯ì€ official ê¶Œì¥)", choices=[], value=None, interactive=True)
        matches_state = gr.State([])          # ì˜µì…˜: í•„ìš”ì‹œ í™•ì¥ìš©
        player_stats_state = gr.State({})     # {"rows": [...]}

        load_btn.click(
            fn=ui_load_matches_selectable,
            inputs=[match_date, cb_epl, cb_laliga, cb_seriea, cb_bundes, cb_ligue1],  # â˜… ìˆ˜ì •
            outputs=[matches_html, match_select, matches_state]
        )

        fetch_stats_btn = gr.Button("ì„ ìˆ˜ ìŠ¤íƒ¯ ë¶ˆëŸ¬ì˜¤ê¸°")
        stats_html = gr.HTML(label="ì„ ìˆ˜ë³„ ìŠ¤íƒ¯")
        fetch_stats_btn.click(
            fn=ui_fetch_player_stats,
            inputs=[match_select],
            outputs=[stats_html, player_stats_state]
        )

        # (analysis_group ë‚´ë¶€, ê¸°ì¡´ êµ¬ì„± í•˜ë‹¨ì— ì¶”ê°€)
        question_full = gr.Textbox(label="ğŸ’¬ ì§ˆë¬¸ (ì „ ë°ì´í„° ê¸°ë°˜)", placeholder="ì˜ˆ) ì´ ê²½ê¸°ì˜ ì „ìˆ ì  ì°¨ì´ì™€ ê²°ì •ì  ìš”ì¸ì„ ë¶„ì„í•´ì¤˜")
        answer_full   = gr.Textbox(label="ğŸ“ LLM ë‹µë³€", lines=12)
        analyze_full_btn = gr.Button("ğŸ§  ì „ì²´ ë°ì´í„°ë¡œ ë¶„ì„í•˜ê¸° (í‘œì‹œ ì•ˆ í•¨)")

        analyze_full_btn.click(
            fn=ui_analyze_match_full_auto,
            inputs=[question_full, match_select, matches_state],
            outputs=[answer_full]
        )


    # ì´ë²¤íŠ¸ ë°”ì¸ë”© (ê·¸ëŒ€ë¡œ ìœ ì§€)
    preset.change(fn=apply_preset, inputs=preset, outputs=[start_date_input, end_date_input])
    submit_button.click(
        ask_question,
        inputs=[question_input, start_date_input, end_date_input, hard_only_check],
        outputs=[answer_output, links_output]
    )

    # ë²„íŠ¼ìœ¼ë¡œ í™”ë©´ ì „í™˜
    btn_news.click(
        fn=lambda: (gr.update(visible=True), gr.update(visible=False)),
        inputs=None,
        outputs=[news_group, analysis_group],
    )
    btn_analysis.click(
        fn=lambda: (gr.update(visible=False), gr.update(visible=True)),
        inputs=None,
        outputs=[news_group, analysis_group],
    )

    demo.load(create_rag_chain, inputs=None, outputs=status_output)

# Gradio Blocks ì •ì˜ê°€ ëª¨ë‘ ëë‚œ ë’¤, launch ì§ì „ì— ì¶”ê°€
if AUTO_INGEST and not globals().get("_ingest_thread_started", False):
    threading.Thread(target=_ingest_loop, daemon=True).start()
    globals()["_ingest_thread_started"] = True
    print(f"[ingest] auto-run enabled every {INGEST_EVERY_MIN} min")


demo.launch(share=True)